@article{tibshirani2001estimating,
  title={Estimating the number of clusters in a data set via the gap statistic},
  author={Tibshirani, Robert and Walther, Guenther and Hastie, Trevor},
  journal={Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume={63},
  number={2},
  pages={411--423},
  year={2001},
  publisher={Wiley Online Library}
}

@article{McInnes2018, 
	doi = {10.21105/joss.00861}, 
	url = {https://doi.org/10.21105/joss.00861}, 
	year = {2018}, publisher = {The Open Journal}, 
	volume = {3}, 
	number = {29}, 
	pages = {861}, 
	author = {Leland McInnes and John Healy and Nathaniel Saul and Lukas Großberger}, 
	title = {UMAP: Uniform Manifold Approximation and Projection}, 
	journal = {Journal of Open Source Software} 
}

@article{zelnik2004self,
  title={Self-tuning spectral clustering},
  author={Zelnik-Manor, Lihi and Perona, Pietro},
  journal={Advances in neural information processing systems},
  volume={17},
  year={2004}
}

@article{ng2001spectral,
	title={On spectral clustering: Analysis and an algorithm},
	author={Ng, Andrew and Jordan, Michael and Weiss, Yair},
	journal={Advances in neural information processing systems},
	volume={14},
	year={2001}
}

@book{cover1991elements,
	title={Elements of Information Theory},
	author={Cover, Thomas M. and Thomas, Joy A.},
	year={1991},
	publisher={Wiley-Interscience},
	address={New York},
	isbn={978-0-471-06259-2}
}

@article{halkidi2002cluster,
	title={Cluster validity methods: Part I},
	author={Halkidi, Maria and Batistakis, Yannis and Vazirgiannis, Michalis},
	journal={ACM SIGMOD Record},
	volume={31},
	number={2},
	pages={40--45},
	year={2002},
	publisher={ACM New York, NY, USA}
}

@article{cover1991information,
  title={Information theory and the stock market},
  author={Cover, Thomas M and Thomas, Joy A},
  journal={Elements of Information Theory. Wiley Inc., New York},
  pages={543--556},
  year={1991}
} 

@article{ward1963hierarchical,
	title={Hierarchical grouping to optimize an objective function},
	author={Ward Jr, Joe H},
	journal={Journal of the American Statistical Association},
	volume={58},
	number={301},
	pages={236--244},
	year={1963},
	publisher={Taylor \& Francis}
}


@book{mclachlan2000finite,
	title={Finite Mixture Models},
	author={McLachlan, Geoffrey J. and Peel, David},
	year={2000},
	publisher={Wiley-Interscience},
	address={New York},
	isbn={9780471006268}
}

@article{govaert2003clustering,
	title={Clustering with block mixture models},
	author={Govaert, Gérard and Nadif, Mohamed},
	journal={Pattern Recognition},
	volume={36},
	number={2},
	pages={463--473},
	year={2003},
	publisher={Elsevier}
}



@inproceedings{dhillon2004kernel,
	title={Kernel k-means, spectral clustering and normalized cuts},
	author={Dhillon, Inderjit S and Guan, Yuqiang and Kulis, Brian},
	booktitle={Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining},
	pages={551--556},
	year={2004},
	organization={ACM}
}

@techreport{arthur2007kmeanspp,
	number = {2006-13},
	month = {June},
	author = {David Arthur and Sergei Vassilvitskii},
	title = {k-means++: The Advantages of Careful Seeding},
	type = {Technical Report},
	publisher = {Stanford},
	institution = {Stanford InfoLab},
	year = {2006},
	keywords = {k-means, clustering, seeding},
	url = {http://ilpubs.stanford.edu:8090/778/},
	abstract = {The k-means method is a widely used clustering technique that seeks to minimize the average squared distance between points in the same cluster. Although it offers no accuracy guarantees, its simplicity and speed are very appealing in practice. By augmenting k-means with a simple, randomized seeding technique, we obtain an algorithm that is $O(\log k)$-competitive with the optimal clustering. Experiments show our augmentation improves both the speed and the accuracy of k-means, often quite dramatically.}
}

@article{shi2000normalized,
	title={Normalized cuts and image segmentation},
	author={Shi, Jianbo and Malik, Jitendra},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
	volume={22},
	number={8},
	pages={888--905},
	year={2000},
	publisher={IEEE}
}


@article{dempster1977maximum,
	title={Maximum likelihood from incomplete data via the EM algorithm},
	author={Dempster, Arthur P and Laird, Nan M and Rubin, Donald B},
	journal={Journal of the Royal Statistical Society: Series B (Methodological)},
	volume={39},
	number={1},
	pages={1--22},
	year={1977},
	publisher={Wiley Online Library}
}

@article{Verhaak2010,
	title={Integrated genomic analysis identifies clinically relevant subtypes of glioblastoma characterized by abnormalities in PDGFRA, IDH1, EGFR, and NF1},
	author={Verhaak, Roel G.W. and Hoadley, Katherine A. and Purdom, Elizabeth and Wang, Victoria and Qi, Yuexin and Wilkerson, Matthew D. and Miller, Charlie R. and Ding, Li and Golub, Todd and Mesirov, Jill P. and Alexe, Gabriela and Lawrence, Michael and O’Kelly, Michael and Tamayo, Pablo and Weir, Bruce A. and Gabriel, Stacey and Winckler, Wendy and Gupta, Shubhada and Bengtsson, Henrik and Jakkula, Lakshmi and Feiler, Heidi S. and Hodgson, Jennifer G. and James, Christopher D. and Sarkaria, Jann N. and Brennan, Cameron and Kahn, Arnold and Spellman, Paul T. and Wilson, Richard K. and Speed, Terence P. and Gray, Joe W. and Meyerson, Matthew and Getz, Gad and Perou, Charles M. and Hayes, D. Neil},
	journal={Cancer Cell},
	volume={17},
	number={1},
	pages={98--110},
	year={2010},
	publisher={Elsevier}
}

@article{Eisen1998,
	title={Cluster analysis and display of genome-wide expression patterns},
	author={Eisen, Michael B. and Spellman, Paul T. and Brown, Patrick O. and Botstein, David},
	journal={Proceedings of the National Academy of Sciences},
	volume={95},
	number={25},
	pages={14863--14868},
	year={1998},
	publisher={National Acad Sciences}
}


@article{latouche2011,
	author = {Pierre Latouche and Etienne Birmel{\'e} and Christophe Ambroise},
	title = {{Overlapping stochastic block models with application to the French political blogosphere}},
	volume = {5},
	journal = {The Annals of Applied Statistics},
	number = {1},
	publisher = {Institute of Mathematical Statistics},
	pages = {309 -- 336},
	keywords = {blockmodels, global and local variational techniques, overlapping clusters, Random graph models},
	year = {2011},
	doi = {10.1214/10-AOAS382},
	URL = {https://doi.org/10.1214/10-AOAS382}
}



@article{jacobs1991adaptive,
	title={Adaptive mixtures of local experts},
	author={Jacobs, Robert A and Jordan, Michael I and Nowlan, Steven J and Hinton, Geoffrey E},
	journal={Neural computation},
	volume={3},
	number={1},
	pages={79--87},
	year={1991},
	publisher={MIT Press}
}

@article{gao2021git,
	title={Git: Clustering based on graph of intensity topology},
	author={Gao, Zhangyang and Lin, Haitao and Tan, Cheng and Wu, Lirong and Li, Stan and others},
	journal={arXiv preprint arXiv:2110.01274},
	year={2021}
}

@article{cai2014large,
	title={Large scale spectral clustering via landmark-based sparse representation},
	author={Cai, Deng and Chen, Xinlei},
	journal={IEEE transactions on cybernetics},
	volume={45},
	number={8},
	pages={1669--1680},
	year={2014},
	publisher={IEEE}
}
@article{chen2010parallel,
	title={Parallel spectral clustering in distributed systems},
	author={Chen, Wen-Yen and Song, Yangqiu and Bai, Hongjie and Lin, Chih-Jen and Chang, Edward Y},
	journal={IEEE transactions on pattern analysis and machine intelligence},
	volume={33},
	number={3},
	pages={568--586},
	year={2010},
	publisher={IEEE}
}

	@article{huang2019ultra,
	title={Ultra-scalable spectral clustering and ensemble clustering},
	author={Huang, Dong and Wang, Chang-Dong and Wu, Jian-Sheng and Lai, Jian-Huang and Kwoh, Chee-Keong},
	journal={IEEE Transactions on Knowledge and Data Engineering},
	volume={32},
	number={6},
	pages={1212--1226},
	year={2019},
	publisher={IEEE}
}

@article{Cortes1995,
	title={Support-vector networks},
	author={Cortes, Corinna and Vapnik, Vladimir},
	journal={Machine learning},
	volume={20},
	number={3},
	pages={273--297},
	year={1995},
	publisher={Springer}
}



@article{computo,
  title = {Computo: reproducible computational/algorithmic contributions in statistics and machine learning},
  author = {{Computo Team}},
  year = {2021},
  journal = {computo}
}

@Manual{R-base,
  title = {R: A Language and Environment for Statistical Computing},
  author = {{R Core Team}},
  organization = {R Foundation for Statistical Computing},
  address = {Vienna, Austria},
  year = {2020},
  url = {https://www.R-project.org/},
}

@Manual{R-reticulate,
  title = {reticulate: Interface to Python},
  author = {Kevin Ushey and JJ Allaire and Yuan Tang},
  year = {2020},
  note = {R package version 1.18},
  url = {https://github.com/rstudio/reticulate},
}

@article{perez2011python,
    title	= {Python: an ecosystem for scientific computing},
    author	= {Perez, Fernando and Granger, Brian E and Hunter, John D},
    journal	= {Computing in Science \\& Engineering},
    volume	= {13},
    number	= {2},
    pages	= {13--21},
    year	= {2011},
    publisher	= {AIP Publishing}
}

@inproceedings{macqueen1967some,
	title={Some methods for classification and analysis of multivariate observations},
	author={MacQueen, James and others},
	booktitle={Proceedings of the fifth Berkeley symposium on mathematical statistics and probability},
	volume={1},
	pages={281--297},
	year={1967},
	organization={Oakland, CA, USA}
}

@Article{Quinlan2021,
	author={Quinlan, Jos{\'e} J.
	and Quintana, Fernando A.
	and Page, Garritt L.},
	title={On a class of repulsive mixture models},
	journal={TEST},
	year={2021},
	month={Jun},
	day={01},
	volume={30},
	number={2},
	pages={445-461},
	abstract={Finite or infinite mixture models are routinely used in Bayesian statistical practice for tasks such as clustering or density estimation. Such models are very attractive due to their flexibility and tractability. However, a common problem in fitting these or other discrete models to data is that they tend to produce a large number of overlapping clusters. Some attention has been given in the statistical literature to models that include a repulsive feature, i.e., that encourage separation of mixture components. We study here a method that has been shown to achieve this goal without sacrificing flexibility or model fit. The model is a special case of Gibbs measures, with a parameter that controls the level of repulsion that allows construction of d-dimensional probability densities whose coordinates tend to repel each other. This approach was successfully used for density regression in Quinlan et al. (J Stat Comput Simul 88(15):2931--2947, 2018). We detail some of the global properties of the repulsive family of distributions and offer some further insight by means of a small simulation study.},
	issn={1863-8260},
	doi={10.1007/s11749-020-00726-y},
	url={https://doi.org/10.1007/s11749-020-00726-y}
}

@InProceedings{pmlr-v37-shamir15,
	title = 	 {A Stochastic PCA and SVD Algorithm with an Exponential Convergence Rate},
	author = 	 {Shamir, Ohad},
	booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
	pages = 	 {144--152},
	year = 	 {2015},
	editor = 	 {Bach, Francis and Blei, David},
	volume = 	 {37},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {Lille, France},
	month = 	 {07--09 Jul},
	publisher =    {PMLR},
	pdf = 	 {http://proceedings.mlr.press/v37/shamir15.pdf},
	url = 	 {https://proceedings.mlr.press/v37/shamir15.html},
	abstract = 	 {We describe and analyze a simple algorithm for principal component analysis and singular value decomposition, VR-PCA, which uses computationally cheap stochastic iterations, yet converges exponentially fast to the optimal solution. In contrast, existing algorithms suffer either from slow convergence, or computationally intensive iterations whose runtime scales with the data size. The algorithm builds on a recent variance-reduced stochastic gradient technique, which was previously analyzed for strongly convex optimization, whereas here we apply it to an inherently non-convex problem, using a very different analysis.}
}

@phdthesis{ambroise1996approche,
	title={Approche probabiliste en classification automatique et contraintes de voisinage},
	author={Ambroise, Christophe},
	year={1996},
	school={Compi{\`e}gne}
}

@article{kohonen1990self,
	title={The self-organizing map},
	author={Kohonen, Teuvo},
	journal={Proceedings of the IEEE},
	volume={78},
	number={9},
	pages={1464--1480},
	year={1990},
	publisher={IEEE}
}
@article{von2007tutorial,
	title={A tutorial on spectral clustering},
	author={Von Luxburg, Ulrike},
	journal={Statistics and computing},
	volume={17},
	pages={395--416},
	year={2007},
	publisher={Springer}
}


@inproceedings{ester1996density,
	title={A density-based algorithm for discovering clusters in large spatial databases with noise},
	author={Ester, Martin and Kriegel, Hans-Peter and Sander, J{\"o}rg and Xu, Xiaowei and others},
	booktitle={kdd},
	volume={96},
	pages={226--231},
	year={1996}
}

@ARTICLE{vanderGeeretal2000,
	author  = {van der Geer, J. and Hanraads, J. A. J. and Lupton, R. A.},
	title   = {The art of writing a scientific article},
	journal = {J. Sci. Commun.}, 
	volume  = {163},
	year    = {2000},
	pages   = {51-59}
}

@BOOK{StrunkWhite1979,
	author  = {Strunk Jr., W. and White, E. B.},
	title   = {The Elements of Style},
	edition = {3rd},
	address = {New York, NY},
	publisher = {Macmillan},
	year    = {1979}
}

@INCOLLECTION{MettamAdams1999,
	author  = {Mettam, G. R. and Adams, L. B.},
	title   = {How to prepare an electronic version of your article},
	editor  = {Jones, B. S. and Smith, R. Z.},
	booktitle = {Introduction to the Electronic Age},
	address = {New York, NY},
	publisher = {E-Publishing Inc.},
	year    = {1999},
	pages   = {281-304}
}
